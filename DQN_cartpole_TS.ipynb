{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install piglet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcJJ4VwRcHpI",
        "outputId": "5e2968f6-5320-45d1-f826-6db258cf31a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-opengl\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 7,814 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.2 [28.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.2 [864 kB]\n",
            "Fetched 7,814 kB in 1s (7,457 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 120880 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.2_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.2_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Collecting piglet\n",
            "  Downloading piglet-1.0.0-py2.py3-none-any.whl (2.2 kB)\n",
            "Collecting piglet-templates (from piglet)\n",
            "  Downloading piglet_templates-1.3.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.5/67.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (3.1.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (23.1.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from piglet-templates->piglet) (2.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse->piglet-templates->piglet) (0.41.3)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from astunparse->piglet-templates->piglet) (1.16.0)\n",
            "Installing collected packages: piglet-templates, piglet\n",
            "Successfully installed piglet-1.0.0 piglet-templates-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB4402pRNUJe",
        "outputId": "83fa63d2-81e5-47e6-9e2a-a0b9bc45834b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Nov  8 14:06:40 2023\n",
        "\n",
        "@author: chaitrag\n",
        "\"\"\"\n",
        "from pyvirtualdisplay import Display\n",
        "Display().start()\n",
        "\n",
        "import gym\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "\n",
        "ENV_NAME_2= \"CartPole-v1\"\n",
        "input_dim =4\n",
        "#ENV_NAME_3 = \"MountainCar-v0\"\n",
        "#input_dim=2\n",
        "\n",
        "env = gym.make(ENV_NAME_2)#, render_mode=\"human\")\n",
        "\n",
        "# Define hyperparameters\n",
        "gamma = 0.95 #discount\n",
        "epsilon = 1.0 #explore rate\n",
        "epsilon_min = 0.001\n",
        "epsilon_decay = .9\n",
        "learning_rate = 0.0001\n",
        "batch_size = 10\n",
        "memory_size = 100000000\n",
        "episode_length = 2000\n",
        "target_update_frequency = 2  # Update the target network every N episodes\n",
        "\n",
        "# Define the Q-network\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 256)\n",
        "        self.fc3 = nn.Linear(256, output_dim)\n",
        "        #self.fc4 = nn.Linear(10, 10)\n",
        "        #self.fc5 = nn.Linear(10, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        #x = torch.relu(self.fc4(x))\n",
        "        #x = torch.relu(self.fc5(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create both the main and target networks\n",
        "input_dim = input_dim\n",
        "output_dim = env.action_space.n\n",
        "main_network = QNetwork(input_dim, output_dim)\n",
        "target_network = QNetwork(input_dim, output_dim)\n",
        "target_network.load_state_dict(main_network.state_dict())  # Initialize target network with main network's weights\n",
        "optimizer = optim.Adam(main_network.parameters(), lr=learning_rate)\n",
        "\n",
        "# Initialize replay memory\n",
        "replay_memory = []\n",
        "\n",
        "# Function to choose an action\n",
        "def choose_action(state):\n",
        "    if np.random.rand() <= epsilon:\n",
        "        return env.action_space.sample()\n",
        "    else:\n",
        "        q_values = main_network(torch.Tensor(state))\n",
        "        return torch.argmax(q_values).item()\n",
        "def get_Q_network_output(state):\n",
        "    return main_network(torch.Tensor(state))"
      ],
      "metadata": {
        "id": "xUMLqxV8ijWb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training loop\n",
        "num_episodes = 100\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    #img = plt.imshow(env.render('rgb_array')) # only call this once\n",
        "    total_reward = 0\n",
        "\n",
        "    for t in range(episode_length):\n",
        "        #img.set_data(env.render('rgb_array')) # just update the data\n",
        "        #display.display(plt.gcf())\n",
        "        #display.clear_output(wait=True)\n",
        "        action = choose_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "        replay_memory.append((state, action, reward, next_state, done))#store experiences into replay memory\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            #print(f\"Episode: {episode + 1}, Total Reward: {total_reward}, Epsilon: {epsilon}\")\n",
        "            break\n",
        "\n",
        "        if len(replay_memory) >= batch_size:\n",
        "            batch = random.sample(replay_memory, batch_size)\n",
        "\n",
        "            for state_batch, action_batch, reward_batch, next_state_batch, done_batch in batch:\n",
        "                state_batch = torch.Tensor(state_batch)\n",
        "                next_state_batch = torch.Tensor(next_state_batch)\n",
        "\n",
        "                q_values = main_network(state_batch)\n",
        "                target = q_values.clone().detach()\n",
        "\n",
        "                if not done_batch:\n",
        "                    target[action_batch] = reward_batch + gamma * torch.max(target_network(next_state_batch))\n",
        "                else:\n",
        "                    target[action_batch] = reward_batch\n",
        "\n",
        "                loss = nn.MSELoss()(q_values, target)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "    print(f\"Episode: {episode + 1}, Total Reward: {total_reward}, Epsilon: {epsilon}\")\n",
        "    # Decay exploration rate\n",
        "    if epsilon > epsilon_min:\n",
        "        epsilon *= epsilon_decay\n",
        "\n",
        "    # Update the target network\n",
        "    if episode % target_update_frequency == 0:\n",
        "        target_network.load_state_dict(main_network.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4RcpUaWizwe",
        "outputId": "973ac01d-6507-4701-ea26-d4638bb372e4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1, Total Reward: 22.0, Epsilon: 1.0\n",
            "Episode: 2, Total Reward: 18.0, Epsilon: 0.9\n",
            "Episode: 3, Total Reward: 16.0, Epsilon: 0.81\n",
            "Episode: 4, Total Reward: 17.0, Epsilon: 0.7290000000000001\n",
            "Episode: 5, Total Reward: 13.0, Epsilon: 0.6561000000000001\n",
            "Episode: 6, Total Reward: 17.0, Epsilon: 0.5904900000000002\n",
            "Episode: 7, Total Reward: 15.0, Epsilon: 0.5314410000000002\n",
            "Episode: 8, Total Reward: 15.0, Epsilon: 0.47829690000000014\n",
            "Episode: 9, Total Reward: 27.0, Epsilon: 0.43046721000000016\n",
            "Episode: 10, Total Reward: 25.0, Epsilon: 0.38742048900000015\n",
            "Episode: 11, Total Reward: 25.0, Epsilon: 0.34867844010000015\n",
            "Episode: 12, Total Reward: 17.0, Epsilon: 0.31381059609000017\n",
            "Episode: 13, Total Reward: 22.0, Epsilon: 0.28242953648100017\n",
            "Episode: 14, Total Reward: 98.0, Epsilon: 0.25418658283290013\n",
            "Episode: 15, Total Reward: 14.0, Epsilon: 0.22876792454961012\n",
            "Episode: 16, Total Reward: 12.0, Epsilon: 0.2058911320946491\n",
            "Episode: 17, Total Reward: 13.0, Epsilon: 0.1853020188851842\n",
            "Episode: 18, Total Reward: 11.0, Epsilon: 0.16677181699666577\n",
            "Episode: 19, Total Reward: 12.0, Epsilon: 0.1500946352969992\n",
            "Episode: 20, Total Reward: 14.0, Epsilon: 0.13508517176729928\n",
            "Episode: 21, Total Reward: 11.0, Epsilon: 0.12157665459056936\n",
            "Episode: 22, Total Reward: 13.0, Epsilon: 0.10941898913151243\n",
            "Episode: 23, Total Reward: 9.0, Epsilon: 0.0984770902183612\n",
            "Episode: 24, Total Reward: 10.0, Epsilon: 0.08862938119652508\n",
            "Episode: 25, Total Reward: 35.0, Epsilon: 0.07976644307687257\n",
            "Episode: 26, Total Reward: 27.0, Epsilon: 0.07178979876918531\n",
            "Episode: 27, Total Reward: 19.0, Epsilon: 0.06461081889226679\n",
            "Episode: 28, Total Reward: 62.0, Epsilon: 0.05814973700304011\n",
            "Episode: 29, Total Reward: 50.0, Epsilon: 0.0523347633027361\n",
            "Episode: 30, Total Reward: 35.0, Epsilon: 0.04710128697246249\n",
            "Episode: 31, Total Reward: 51.0, Epsilon: 0.042391158275216244\n",
            "Episode: 32, Total Reward: 49.0, Epsilon: 0.03815204244769462\n",
            "Episode: 33, Total Reward: 32.0, Epsilon: 0.03433683820292516\n",
            "Episode: 34, Total Reward: 80.0, Epsilon: 0.030903154382632643\n",
            "Episode: 35, Total Reward: 50.0, Epsilon: 0.02781283894436938\n",
            "Episode: 36, Total Reward: 26.0, Epsilon: 0.025031555049932444\n",
            "Episode: 37, Total Reward: 34.0, Epsilon: 0.0225283995449392\n",
            "Episode: 38, Total Reward: 94.0, Epsilon: 0.020275559590445278\n",
            "Episode: 39, Total Reward: 34.0, Epsilon: 0.01824800363140075\n",
            "Episode: 40, Total Reward: 18.0, Epsilon: 0.016423203268260675\n",
            "Episode: 41, Total Reward: 24.0, Epsilon: 0.014780882941434608\n",
            "Episode: 42, Total Reward: 31.0, Epsilon: 0.013302794647291147\n",
            "Episode: 43, Total Reward: 14.0, Epsilon: 0.011972515182562033\n",
            "Episode: 44, Total Reward: 18.0, Epsilon: 0.01077526366430583\n",
            "Episode: 45, Total Reward: 18.0, Epsilon: 0.009697737297875247\n",
            "Episode: 46, Total Reward: 35.0, Epsilon: 0.008727963568087723\n",
            "Episode: 47, Total Reward: 19.0, Epsilon: 0.00785516721127895\n",
            "Episode: 48, Total Reward: 19.0, Epsilon: 0.007069650490151055\n",
            "Episode: 49, Total Reward: 27.0, Epsilon: 0.00636268544113595\n",
            "Episode: 50, Total Reward: 54.0, Epsilon: 0.005726416897022355\n",
            "Episode: 51, Total Reward: 57.0, Epsilon: 0.00515377520732012\n",
            "Episode: 52, Total Reward: 33.0, Epsilon: 0.004638397686588107\n",
            "Episode: 53, Total Reward: 26.0, Epsilon: 0.0041745579179292966\n",
            "Episode: 54, Total Reward: 25.0, Epsilon: 0.003757102126136367\n",
            "Episode: 55, Total Reward: 40.0, Epsilon: 0.00338139191352273\n",
            "Episode: 56, Total Reward: 42.0, Epsilon: 0.0030432527221704573\n",
            "Episode: 57, Total Reward: 60.0, Epsilon: 0.0027389274499534117\n",
            "Episode: 58, Total Reward: 89.0, Epsilon: 0.0024650347049580707\n",
            "Episode: 59, Total Reward: 367.0, Epsilon: 0.0022185312344622636\n",
            "Episode: 60, Total Reward: 257.0, Epsilon: 0.001996678111016037\n",
            "Episode: 61, Total Reward: 255.0, Epsilon: 0.0017970102999144335\n",
            "Episode: 62, Total Reward: 229.0, Epsilon: 0.0016173092699229901\n",
            "Episode: 63, Total Reward: 261.0, Epsilon: 0.0014555783429306911\n",
            "Episode: 64, Total Reward: 124.0, Epsilon: 0.001310020508637622\n",
            "Episode: 65, Total Reward: 209.0, Epsilon: 0.0011790184577738598\n",
            "Episode: 66, Total Reward: 330.0, Epsilon: 0.0010611166119964739\n",
            "Episode: 67, Total Reward: 332.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 68, Total Reward: 220.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 69, Total Reward: 206.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 70, Total Reward: 461.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 71, Total Reward: 356.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 72, Total Reward: 254.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 73, Total Reward: 185.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 74, Total Reward: 219.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 75, Total Reward: 239.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 76, Total Reward: 277.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 77, Total Reward: 233.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 78, Total Reward: 249.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 79, Total Reward: 287.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 80, Total Reward: 357.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 81, Total Reward: 299.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 82, Total Reward: 236.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 83, Total Reward: 293.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 84, Total Reward: 248.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 85, Total Reward: 412.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 86, Total Reward: 296.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 87, Total Reward: 268.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 88, Total Reward: 220.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 89, Total Reward: 290.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 90, Total Reward: 315.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 91, Total Reward: 235.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 92, Total Reward: 244.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 93, Total Reward: 242.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 94, Total Reward: 271.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 95, Total Reward: 266.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 96, Total Reward: 463.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 97, Total Reward: 296.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 98, Total Reward: 346.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 99, Total Reward: 250.0, Epsilon: 0.0009550049507968265\n",
            "Episode: 100, Total Reward: 306.0, Epsilon: 0.0009550049507968265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "#epsilon = 50\n",
        "TEST_EPISODES = 2\n",
        "total_reward = 0\n",
        "img = plt.imshow(env.render('rgb_array')) # only call this once\n",
        "for test_episode in range(TEST_EPISODES):\n",
        "    state = env.reset()\n",
        "    while True:\n",
        "        img.set_data(env.render('rgb_array')) # just update the data\n",
        "        display.display(plt.gcf())\n",
        "        display.clear_output(wait=True)\n",
        "        action = choose_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "        if done:\n",
        "            #print(f\"Episode: {test_episode + 1}, Total Reward: {total_reward}, Epsilon: {epsilon}\")\n",
        "            break\n",
        "average_reward = total_reward / TEST_EPISODES\n",
        "print(f\"average reward:{average_reward} \")\n",
        "if average_reward > 200:\n",
        "    print (\"Good job: Total reward exceeded threshold of 500\")\n",
        "else:\n",
        "    print (\"You can do better: Total reward did not exceed threshold of 500\")\n",
        "#Threshold for reward for cart_pole_v1 500\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "9o4X5SmANyh7",
        "outputId": "e2705637-d3ad-4c23-b927-64d3538dd8d9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average reward:267.0 \n",
            "Good job: Total reward exceeded threshold of 500\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmQklEQVR4nO3dfXBUVZ7/8U+HJC0QumOApJMhQRQGiBCcBQy9zrjOkiFAdGWNVeqwEGcpKNnEGgjDYGYZEWfKsLi1o84q/LG74laJjEyJrig4MUhYNTyYIcuTZoQfM8ElnTBS6Q7RdB76/P6wuLWtqOmQ0Cf4flXdqtx7vuf2uadS1Z+6T+0yxhgBAABYJCHeAwAAAPg8AgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsE5cA8rTTz+t6667Ttdcc43y8/N18ODBeA4HAABYIm4B5Te/+Y3Ky8u1bt06/f73v9e0adNUWFiolpaWeA0JAABYwhWvHwvMz8/XzJkz9a//+q+SpEgkouzsbD344IN66KGH4jEkAABgicR4fGhnZ6fq6upUUVHhbEtISFBBQYFqa2u/UB8OhxUOh531SCSi8+fPa+TIkXK5XFdkzAAA4PIYY9TW1qasrCwlJHz1RZy4BJQ///nP6unpUUZGRtT2jIwMffDBB1+or6ys1Pr166/U8AAAwAA6c+aMxowZ85U1cQkosaqoqFB5ebmzHgwGlZOTozNnzsjj8cRxZAAAoLdCoZCys7M1YsSIr62NS0AZNWqUhgwZoubm5qjtzc3N8vl8X6h3u91yu91f2O7xeAgoAAAMMr25PSMuT/EkJydr+vTpqq6udrZFIhFVV1fL7/fHY0gAAMAicbvEU15erpKSEs2YMUM333yznnjiCbW3t+tHP/pRvIYEAAAsEbeAcs899+jcuXN6+OGHFQgEdNNNN2n37t1fuHEWAAB888TtPSiXIxQKyev1KhgMcg8KAACDRCzf3/wWDwAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdfo9oDzyyCNyuVxRy6RJk5z2jo4OlZaWauTIkUpJSVFxcbGam5v7exgAAGAQG5AzKDfeeKOampqc5e2333baVq5cqVdffVXbt29XTU2Nzp49q7vuumsghgEAAAapxAHZaWKifD7fF7YHg0H9+7//u7Zu3aq//uu/liQ9++yzmjx5svbv369Zs2YNxHAAAMAgMyBnUD788ENlZWXp+uuv18KFC9XY2ChJqqurU1dXlwoKCpzaSZMmKScnR7W1tV+6v3A4rFAoFLUAAICrV78HlPz8fG3ZskW7d+/Wpk2bdPr0aX3ve99TW1ubAoGAkpOTlZqaGtUnIyNDgUDgS/dZWVkpr9frLNnZ2f09bAAAYJF+v8Qzb9485++8vDzl5+dr7NixevHFFzV06NA+7bOiokLl5eXOeigUIqQAAHAVG/DHjFNTU/Xtb39bJ0+elM/nU2dnp1pbW6NqmpubL3nPykVut1sejydqAQAAV68BDygXLlzQqVOnlJmZqenTpyspKUnV1dVOe0NDgxobG+X3+wd6KAAAYJDo90s8P/nJT3THHXdo7NixOnv2rNatW6chQ4bovvvuk9fr1ZIlS1ReXq60tDR5PB49+OCD8vv9PMEDAAAc/R5QPvroI9133336+OOPNXr0aH33u9/V/v37NXr0aEnSr371KyUkJKi4uFjhcFiFhYV65pln+nsYAABgEHMZY0y8BxGrUCgkr9erYDDI/SgAAAwSsXx/81s8AADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrxBxQ9u3bpzvuuENZWVlyuVx6+eWXo9qNMXr44YeVmZmpoUOHqqCgQB9++GFUzfnz57Vw4UJ5PB6lpqZqyZIlunDhwmUdCAAAuHrEHFDa29s1bdo0Pf3005ds37hxo5566ilt3rxZBw4c0PDhw1VYWKiOjg6nZuHChTp+/Liqqqq0c+dO7du3T8uWLev7UQAAgKuKyxhj+tzZ5dKOHTu0YMECSZ+dPcnKytKqVav0k5/8RJIUDAaVkZGhLVu26N5779X777+v3NxcHTp0SDNmzJAk7d69W/Pnz9dHH32krKysr/3cUCgkr9erYDAoj8fT1+EDAIArKJbv7369B+X06dMKBAIqKChwtnm9XuXn56u2tlaSVFtbq9TUVCecSFJBQYESEhJ04MCBS+43HA4rFApFLQAA4OrVrwElEAhIkjIyMqK2Z2RkOG2BQEDp6elR7YmJiUpLS3NqPq+yslJer9dZsrOz+3PYAADAMoPiKZ6KigoFg0FnOXPmTLyHBAAABlC/BhSfzydJam5ujtre3NzstPl8PrW0tES1d3d36/z5807N57ndbnk8nqgFAABcvfo1oIwbN04+n0/V1dXOtlAopAMHDsjv90uS/H6/WltbVVdX59Ts2bNHkUhE+fn5/TkcAAAwSCXG2uHChQs6efKks3769GnV19crLS1NOTk5WrFihX75y19qwoQJGjdunH7+858rKyvLedJn8uTJmjt3rpYuXarNmzerq6tLZWVluvfee3v1BA8AALj6xRxQ3nvvPX3/+9931svLyyVJJSUl2rJli37605+qvb1dy5YtU2trq7773e9q9+7duuaaa5w+zz//vMrKyjR79mwlJCSouLhYTz31VD8cDgAAuBpc1ntQ4oX3oAAAMPjE7T0oAAAA/YGAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOjEHlH379umOO+5QVlaWXC6XXn755aj2+++/Xy6XK2qZO3duVM358+e1cOFCeTwepaamasmSJbpw4cJlHQgAALh6xBxQ2tvbNW3aND399NNfWjN37lw1NTU5ywsvvBDVvnDhQh0/flxVVVXauXOn9u3bp2XLlsU+egAAcFVKjLXDvHnzNG/evK+scbvd8vl8l2x7//33tXv3bh06dEgzZsyQJP3617/W/Pnz9c///M/KysqKdUgAAOAqMyD3oOzdu1fp6emaOHGili9fro8//thpq62tVWpqqhNOJKmgoEAJCQk6cODAJfcXDocVCoWiFgAAcPXq94Ayd+5c/ed//qeqq6v1T//0T6qpqdG8efPU09MjSQoEAkpPT4/qk5iYqLS0NAUCgUvus7KyUl6v11mys7P7e9gAAMAiMV/i+Tr33nuv8/fUqVOVl5enG264QXv37tXs2bP7tM+KigqVl5c766FQiJACAMBVbMAfM77++us1atQonTx5UpLk8/nU0tISVdPd3a3z589/6X0rbrdbHo8nagEAAFevAQ8oH330kT7++GNlZmZKkvx+v1pbW1VXV+fU7NmzR5FIRPn5+QM9HAAAMAjEfInnwoULztkQSTp9+rTq6+uVlpamtLQ0rV+/XsXFxfL5fDp16pR++tOfavz48SosLJQkTZ48WXPnztXSpUu1efNmdXV1qaysTPfeey9P8AAAAEmSyxhjYumwd+9eff/73//C9pKSEm3atEkLFizQ4cOH1draqqysLM2ZM0e/+MUvlJGR4dSeP39eZWVlevXVV5WQkKDi4mI99dRTSklJ6dUYQqGQvF6vgsEgl3sAABgkYvn+jjmg2ICAAgDA4BPL9ze/xQMAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYJ2YAkplZaVmzpypESNGKD09XQsWLFBDQ0NUTUdHh0pLSzVy5EilpKSouLhYzc3NUTWNjY0qKirSsGHDlJ6ertWrV6u7u/vyjwYAAFwVYgooNTU1Ki0t1f79+1VVVaWuri7NmTNH7e3tTs3KlSv16quvavv27aqpqdHZs2d11113Oe09PT0qKipSZ2en3n33XT333HPasmWLHn744f47KgAAMKi5jDGmr53PnTun9PR01dTU6NZbb1UwGNTo0aO1detW3X333ZKkDz74QJMnT1Ztba1mzZqlXbt26fbbb9fZs2eVkZEhSdq8ebPWrFmjc+fOKTk5+Ws/NxQKyev1KhgMyuPx9HX4AADgCorl+/uy7kEJBoOSpLS0NElSXV2durq6VFBQ4NRMmjRJOTk5qq2tlSTV1tZq6tSpTjiRpMLCQoVCIR0/fvySnxMOhxUKhaIWAABw9epzQIlEIlqxYoVuueUWTZkyRZIUCASUnJys1NTUqNqMjAwFAgGn5v+Gk4vtF9supbKyUl6v11mys7P7OmwAADAI9DmglJaW6tixY9q2bVt/jueSKioqFAwGneXMmTMD/pkAACB+EvvSqaysTDt37tS+ffs0ZswYZ7vP51NnZ6daW1ujzqI0NzfL5/M5NQcPHoza38WnfC7WfJ7b7Zbb7e7LUAEAwCAU0xkUY4zKysq0Y8cO7dmzR+PGjYtqnz59upKSklRdXe1sa2hoUGNjo/x+vyTJ7/fr6NGjamlpcWqqqqrk8XiUm5t7OccCAACuEjGdQSktLdXWrVv1yiuvaMSIEc49I16vV0OHDpXX69WSJUtUXl6utLQ0eTwePfjgg/L7/Zo1a5Ykac6cOcrNzdWiRYu0ceNGBQIBrV27VqWlpZwlAQAAkmJ8zNjlcl1y+7PPPqv7779f0mcvalu1apVeeOEFhcNhFRYW6plnnom6fPOnP/1Jy5cv1969ezV8+HCVlJRow4YNSkzsXV7iMWMAAAafWL6/L+s9KPFCQAEAYPC5Yu9BAQAAGAgEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACuiMbaF3tdS0ABAABXROjM+72uJaAAAADrEFAAAIB1CCgAAGDARbq7ZGR6XU9AAQAAA6473C6ZSK/rCSgAAGDAdYfbZQgoAADAJt0d7TIRAgoAALBID2dQAACAbS40/z9Fujp7XU9AAQAAA64j2CwT6e51PQEFAABYh4ACAACsQ0ABAAADypiIZHr/kjaJgAIAAAZYpLtTJtITUx8CCgAAGFA9XWFFerpi6kNAAQAAAyrS1aFId+8fMZYIKAAAYID1dHZwBgUAANilI3ROXZ+EYuoTU0CprKzUzJkzNWLECKWnp2vBggVqaGiIqrntttvkcrmilgceeCCqprGxUUVFRRo2bJjS09O1evVqdXf3/uUtAABg8AgHm9X9aWwBJTGW4pqaGpWWlmrmzJnq7u7Wz372M82ZM0cnTpzQ8OHDnbqlS5fq0UcfddaHDRvm/N3T06OioiL5fD69++67ampq0uLFi5WUlKTHHnsspsEDAICrU0wBZffu3VHrW7ZsUXp6uurq6nTrrbc624cNGyafz3fJffzud7/TiRMn9OabbyojI0M33XSTfvGLX2jNmjV65JFHlJyc3IfDAAAAV5PLugclGAxKktLS0qK2P//88xo1apSmTJmiiooKffLJJ05bbW2tpk6dqoyMDGdbYWGhQqGQjh8/fsnPCYfDCoVCUQsAALh6xXQG5f+KRCJasWKFbrnlFk2ZMsXZ/sMf/lBjx45VVlaWjhw5ojVr1qihoUEvvfSSJCkQCESFE0nOeiAQuORnVVZWav369X0dKgAAiBMTicT8kjbpMgJKaWmpjh07prfffjtq+7Jly5y/p06dqszMTM2ePVunTp3SDTfc0KfPqqioUHl5ubMeCoWUnZ3dt4EDAIArJtLTpZ7Ojpj79ekST1lZmXbu3Km33npLY8aM+cra/Px8SdLJkyclST6fT83NzVE1F9e/7L4Vt9stj8cTtQAAAPuZnm71dA1wQDHGqKysTDt27NCePXs0bty4r+1TX18vScrMzJQk+f1+HT16VC0tLU5NVVWVPB6PcnNzYxkOAACw3GdnUD6NuV9Ml3hKS0u1detWvfLKKxoxYoRzz4jX69XQoUN16tQpbd26VfPnz9fIkSN15MgRrVy5Urfeeqvy8vIkSXPmzFFubq4WLVqkjRs3KhAIaO3atSotLZXb7Y75AAAAgL1MT/fAX+LZtGmTgsGgbrvtNmVmZjrLb37zG0lScnKy3nzzTc2ZM0eTJk3SqlWrVFxcrFdffdXZx5AhQ7Rz504NGTJEfr9ff/d3f6fFixdHvTcFAABcHbo62tTR2hRzv5jOoBhjvrI9OztbNTU1X7ufsWPH6vXXX4/lowEAwCDUE/5EnRfOx9yP3+IBAADWIaAAAADrEFAAAMCAMMbImEif+hJQAADAADF9eoJHIqAAAIABYiIRdYcv9KkvAQUAAAwMY9TdQUABAAAWMSai7o72PvUloAAAgAFherrVfu5PfepLQAEAAAMi0tOl9uZTfepLQAEAANYhoAAAAOsQUAAAgHUIKAAAoN8ZYxTp6epzfwIKAAAYEN2fhPrcl4ACAAAGRNenBBQAAGCZTs6gAAAA23xy7o997ktAAQAAA+Ljkwf63JeAAgAArJMY7wEAAAC7RCIRRSKRy9uJMZfVnTMoAAAgyu7duzV06NDLWoYNH6aOjo4+j4EzKAAAIIoxRt3d3Ze1jwSX67L6E1AAAEC/SxmaJJdcCkeuUUtnjjoiKerouNDr/gQUAADQ7671DFWXcetoaI4u9KSqy7gV7mjrdX8CCgAA6HdpnhF6N1isbpfX2WZiuPWVm2QBAEC/8895XF3y9Lk/AQUAAPQ/l+S6jBtlCSgAAMA6BBQAAGAdAgoAAOh3s7yvKsnV9xe1xRRQNm3apLy8PHk8Hnk8Hvn9fu3atctp7+joUGlpqUaOHKmUlBQVFxerubk5ah+NjY0qKirSsGHDlJ6ertWrV1/2y2AAAIBdklxhfe/aF5Uy5LyGuDolGbnU+9fnx/SY8ZgxY7RhwwZNmDBBxhg999xzuvPOO3X48GHdeOONWrlypV577TVt375dXq9XZWVluuuuu/TOO+9Iknp6elRUVCSfz6d3331XTU1NWrx4sZKSkvTYY4/FdOAAAMBeew6f1ujTLQpH/qCz4Rv0SY9XPd3tve7vMubyfs0nLS1Njz/+uO6++26NHj1aW7du1d133y1J+uCDDzR58mTV1tZq1qxZ2rVrl26//XadPXtWGRkZkqTNmzdrzZo1OnfunJKTk3v1maFQSF6vV/fff3+v+wAAgN5pbGzU7t27B2z/wWBQHs9XP4Lc5xe19fT0aPv27Wpvb5ff71ddXZ26urpUUFDg1EyaNEk5OTlOQKmtrdXUqVOdcCJJhYWFWr58uY4fP67vfOc7l/yscDiscDjsrIdCIUnSokWLlJKS0tdDAAAAl/DOO+8MaEDpjZgDytGjR+X3+9XR0aGUlBTt2LFDubm5qq+vV3JyslJTU6PqMzIyFAgEJEmBQCAqnFxsv9j2ZSorK7V+/fovbJ8xY8bXJjAAABCbc+fOxXsIsT/FM3HiRNXX1+vAgQNavny5SkpKdOLEiYEYm6OiokLBYNBZzpw5M6CfBwAA4ivmMyjJyckaP368JGn69Ok6dOiQnnzySd1zzz3q7OxUa2tr1FmU5uZm+Xw+SZLP59PBgwej9nfxKZ+LNZfidrvldrtjHSoAABikLvs9KJFIROFwWNOnT1dSUpKqq6udtoaGBjU2Nsrv90uS/H6/jh49qpaWFqemqqpKHo9Hubm5lzsUAABwlYjpDEpFRYXmzZunnJwctbW1aevWrdq7d6/eeOMNeb1eLVmyROXl5UpLS5PH49GDDz4ov9+vWbNmSZLmzJmj3NxcLVq0SBs3blQgENDatWtVWlrKGRIAAOCIKaC0tLRo8eLFampqktfrVV5ent544w394Ac/kCT96le/UkJCgoqLixUOh1VYWKhnnnnG6T9kyBDt3LlTy5cvl9/v1/Dhw1VSUqJHH320f48KAAAMapf9HpR4uPgelN48Rw0AAGLz2muv6fbbbx+w/ffm+5vf4gEAANYhoAAAAOsQUAAAgHUIKAAAwDp9/i0eAABwdcrIyNCCBQv6fb9dXV167bXXelXLUzwAAOCKiOX7m0s8AADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdWIKKJs2bVJeXp48Ho88Ho/8fr927drltN92221yuVxRywMPPBC1j8bGRhUVFWnYsGFKT0/X6tWr1d3d3T9HAwAArgqJsRSPGTNGGzZs0IQJE2SM0XPPPac777xThw8f1o033ihJWrp0qR599FGnz7Bhw5y/e3p6VFRUJJ/Pp3fffVdNTU1avHixkpKS9Nhjj/XTIQEAgMHOZYwxl7ODtLQ0Pf7441qyZIluu+023XTTTXriiScuWbtr1y7dfvvtOnv2rDIyMiRJmzdv1po1a3Tu3DklJyf36jNDoZC8Xq+CwaA8Hs/lDB8AAFwhsXx/9/kelJ6eHm3btk3t7e3y+/3O9ueff16jRo3SlClTVFFRoU8++cRpq62t1dSpU51wIkmFhYUKhUI6fvz4l35WOBxWKBSKWgAAwNUrpks8knT06FH5/X51dHQoJSVFO3bsUG5uriTphz/8ocaOHausrCwdOXJEa9asUUNDg1566SVJUiAQiAonkpz1QCDwpZ9ZWVmp9evXxzpUAAAwSMUcUCZOnKj6+noFg0H99re/VUlJiWpqapSbm6tly5Y5dVOnTlVmZqZmz56tU6dO6YYbbujzICsqKlReXu6sh0IhZWdn93l/AADAbjFf4klOTtb48eM1ffp0VVZWatq0aXryyScvWZufny9JOnnypCTJ5/Opubk5qubius/n+9LPdLvdzpNDFxcAAHD1uuz3oEQiEYXD4Uu21dfXS5IyMzMlSX6/X0ePHlVLS4tTU1VVJY/H41wmAgAAiOkST0VFhebNm6ecnBy1tbVp69at2rt3r9544w2dOnVKW7du1fz58zVy5EgdOXJEK1eu1K233qq8vDxJ0pw5c5Sbm6tFixZp48aNCgQCWrt2rUpLS+V2uwfkAAEAwOATU0BpaWnR4sWL1dTUJK/Xq7y8PL3xxhv6wQ9+oDNnzujNN9/UE088ofb2dmVnZ6u4uFhr1651+g8ZMkQ7d+7U8uXL5ff7NXz4cJWUlES9NwUAAOCy34MSD7wHBQCAweeKvAcFAABgoBBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrJMZ7AH1hjJEkhUKhOI8EAAD01sXv7Yvf419lUAaUtrY2SVJ2dnacRwIAAGLV1tYmr9f7lTUu05sYY5lIJKKGhgbl5ubqzJkz8ng88R7SoBUKhZSdnc089gPmsv8wl/2Deew/zGX/MMaora1NWVlZSkj46rtMBuUZlISEBH3rW9+SJHk8Hv5Z+gHz2H+Yy/7DXPYP5rH/MJeX7+vOnFzETbIAAMA6BBQAAGCdQRtQ3G631q1bJ7fbHe+hDGrMY/9hLvsPc9k/mMf+w1xeeYPyJlkAAHB1G7RnUAAAwNWLgAIAAKxDQAEAANYhoAAAAOsMyoDy9NNP67rrrtM111yj/Px8HTx4MN5Dss6+fft0xx13KCsrSy6XSy+//HJUuzFGDz/8sDIzMzV06FAVFBToww8/jKo5f/68Fi5cKI/Ho9TUVC1ZskQXLly4gkcRf5WVlZo5c6ZGjBih9PR0LViwQA0NDVE1HR0dKi0t1ciRI5WSkqLi4mI1NzdH1TQ2NqqoqEjDhg1Tenq6Vq9ere7u7it5KHG1adMm5eXlOS+58vv92rVrl9POHPbdhg0b5HK5tGLFCmcb89k7jzzyiFwuV9QyadIkp515jDMzyGzbts0kJyeb//iP/zDHjx83S5cuNampqaa5uTneQ7PK66+/bv7xH//RvPTSS0aS2bFjR1T7hg0bjNfrNS+//LL5n//5H/M3f/M3Zty4cebTTz91aubOnWumTZtm9u/fb/77v//bjB8/3tx3331X+Ejiq7Cw0Dz77LPm2LFjpr6+3syfP9/k5OSYCxcuODUPPPCAyc7ONtXV1ea9994zs2bNMn/5l3/ptHd3d5spU6aYgoICc/jwYfP666+bUaNGmYqKingcUlz813/9l3nttdfMH/7wB9PQ0GB+9rOfmaSkJHPs2DFjDHPYVwcPHjTXXXedycvLMz/+8Y+d7cxn76xbt87ceOONpqmpyVnOnTvntDOP8TXoAsrNN99sSktLnfWenh6TlZVlKisr4zgqu30+oEQiEePz+czjjz/ubGttbTVut9u88MILxhhjTpw4YSSZQ4cOOTW7du0yLpfL/O///u8VG7ttWlpajCRTU1NjjPls3pKSksz27dudmvfff99IMrW1tcaYz8JiQkKCCQQCTs2mTZuMx+Mx4XD4yh6ARa699lrzb//2b8xhH7W1tZkJEyaYqqoq81d/9VdOQGE+e2/dunVm2rRpl2xjHuNvUF3i6ezsVF1dnQoKCpxtCQkJKigoUG1tbRxHNricPn1agUAgah69Xq/y8/OdeaytrVVqaqpmzJjh1BQUFCghIUEHDhy44mO2RTAYlCSlpaVJkurq6tTV1RU1l5MmTVJOTk7UXE6dOlUZGRlOTWFhoUKhkI4fP34FR2+Hnp4ebdu2Te3t7fL7/cxhH5WWlqqoqChq3iT+J2P14YcfKisrS9dff70WLlyoxsZGScyjDQbVjwX++c9/Vk9PT9Q/gyRlZGTogw8+iNOoBp9AICBJl5zHi22BQEDp6elR7YmJiUpLS3NqvmkikYhWrFihW265RVOmTJH02TwlJycrNTU1qvbzc3mpub7Y9k1x9OhR+f1+dXR0KCUlRTt27FBubq7q6+uZwxht27ZNv//973Xo0KEvtPE/2Xv5+fnasmWLJk6cqKamJq1fv17f+973dOzYMebRAoMqoADxVFpaqmPHjuntt9+O91AGpYkTJ6q+vl7BYFC//e1vVVJSopqamngPa9A5c+aMfvzjH6uqqkrXXHNNvIczqM2bN8/5Oy8vT/n5+Ro7dqxefPFFDR06NI4jgzTInuIZNWqUhgwZ8oW7qJubm+Xz+eI0qsHn4lx91Tz6fD61tLREtXd3d+v8+fPfyLkuKyvTzp079dZbb2nMmDHOdp/Pp87OTrW2tkbVf34uLzXXF9u+KZKTkzV+/HhNnz5dlZWVmjZtmp588knmMEZ1dXVqaWnRX/zFXygxMVGJiYmqqanRU089pcTERGVkZDCffZSamqpvf/vbOnnyJP+XFhhUASU5OVnTp09XdXW1sy0Siai6ulp+vz+OIxtcxo0bJ5/PFzWPoVBIBw4ccObR7/ertbVVdXV1Ts2ePXsUiUSUn59/xcccL8YYlZWVaceOHdqzZ4/GjRsX1T59+nQlJSVFzWVDQ4MaGxuj5vLo0aNRga+qqkoej0e5ublX5kAsFIlEFA6HmcMYzZ49W0ePHlV9fb2zzJgxQwsXLnT+Zj775sKFCzp16pQyMzP5v7RBvO/SjdW2bduM2+02W7ZsMSdOnDDLli0zqampUXdR47M7/A8fPmwOHz5sJJl/+Zd/MYcPHzZ/+tOfjDGfPWacmppqXnnlFXPkyBFz5513XvIx4+985zvmwIED5u233zYTJkz4xj1mvHz5cuP1es3evXujHkX85JNPnJoHHnjA5OTkmD179pj33nvP+P1+4/f7nfaLjyLOmTPH1NfXm927d5vRo0d/ox5FfOihh0xNTY05ffq0OXLkiHnooYeMy+Uyv/vd74wxzOHl+r9P8RjDfPbWqlWrzN69e83p06fNO++8YwoKCsyoUaNMS0uLMYZ5jLdBF1CMMebXv/61ycnJMcnJyebmm282+/fvj/eQrPPWW28ZSV9YSkpKjDGfPWr885//3GRkZBi3221mz55tGhoaovbx8ccfm/vuu8+kpKQYj8djfvSjH5m2trY4HE38XGoOJZlnn33Wqfn000/NP/zDP5hrr73WDBs2zPzt3/6taWpqitrPH//4RzNv3jwzdOhQM2rUKLNq1SrT1dV1hY8mfv7+7//ejB071iQnJ5vRo0eb2bNnO+HEGObwcn0+oDCfvXPPPfeYzMxMk5ycbL71rW+Ze+65x5w8edJpZx7jy2WMMfE5dwMAAHBpg+oeFAAA8M1AQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdf4/uexfJ/gBKqcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}